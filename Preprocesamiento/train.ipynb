{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms, datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters and DataLoaders\n",
    "PATH = './model_test_5.pth'\n",
    "batch_size = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_transform = transforms.Compose([\n",
    "    transforms.RandomChoice([\n",
    "        transforms.CenterCrop(200),\n",
    "        transforms.RandomAffine(30, fillcolor=128),\n",
    "        transforms.RandomAffine(0,shear=(0,40), fillcolor=128)\n",
    "    ]),\n",
    "    transforms.Resize(256),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])\n",
    "\n",
    "trainset = datasets.ImageFolder(root='./train_img', transform=data_transform)\n",
    "trainset.idx_to_class = {v: k for k, v in trainset.class_to_idx.items()}\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "testset = datasets.ImageFolder(root='./test_img', transform=transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "]))\n",
    "testset.idx_to_class = {v: k for k, v in testset.class_to_idx.items()}\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
    "                                          shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'aceite',\n",
       " 1: 'agua',\n",
       " 2: 'arroz',\n",
       " 3: 'azucar',\n",
       " 4: 'cafe',\n",
       " 5: 'caramelo',\n",
       " 6: 'cereal',\n",
       " 7: 'chips',\n",
       " 8: 'chocolate',\n",
       " 9: 'especias',\n",
       " 10: 'frijoles',\n",
       " 11: 'gaseosa',\n",
       " 12: 'harina',\n",
       " 13: 'jamon',\n",
       " 14: 'jugo',\n",
       " 15: 'leche',\n",
       " 16: 'maiz',\n",
       " 17: 'miel',\n",
       " 18: 'nueces',\n",
       " 19: 'pasta',\n",
       " 20: 'pescado',\n",
       " 21: 'salsatomate',\n",
       " 22: 'te',\n",
       " 23: 'torta',\n",
       " 24: 'vinagre'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset.idx_to_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/lcarranza/.cache/torch/hub/pytorch_vision_v0.5.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 2 GPUs!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Inception3(\n",
       "  (Conv2d_1a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_2a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_2b_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_3b_1x1): BasicConv2d(\n",
       "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_4a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Mixed_5b): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_5c): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_5d): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6a): InceptionB(\n",
       "    (branch3x3): BasicConv2d(\n",
       "      (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6b): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6c): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6d): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6e): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_7a): InceptionD(\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_4): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_7b): InceptionE(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_7c): InceptionE(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "net = torch.hub.load('pytorch/vision:v0.5.0', 'inception_v3', pretrained=False, aux_logits=False)\n",
    "if torch.cuda.device_count() > 1:\n",
    "  print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "  # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "  # net = nn.DataParallel(net)\n",
    "net.to(device)\n",
    "net.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch:  0\n",
      "[1,    96] loss: 1.809\n",
      "Starting Epoch:  1\n",
      "[2,    96] loss: 1.708\n",
      "Starting Epoch:  2\n",
      "[3,    96] loss: 1.608\n",
      "Starting Epoch:  3\n",
      "[4,    96] loss: 1.608\n",
      "Starting Epoch:  4\n",
      "[5,    96] loss: 1.560\n",
      "Starting Epoch:  5\n",
      "[6,    96] loss: 1.497\n",
      "Starting Epoch:  6\n",
      "[7,    96] loss: 1.431\n",
      "Starting Epoch:  7\n",
      "[8,    96] loss: 1.403\n",
      "Starting Epoch:  8\n",
      "[9,    96] loss: 1.334\n",
      "Starting Epoch:  9\n",
      "[10,    96] loss: 1.295\n",
      "Starting Epoch:  10\n",
      "[11,    96] loss: 1.259\n",
      "Starting Epoch:  11\n",
      "[12,    96] loss: 1.185\n",
      "Starting Epoch:  12\n",
      "[13,    96] loss: 1.091\n",
      "Starting Epoch:  13\n",
      "[14,    96] loss: 1.107\n",
      "Starting Epoch:  14\n",
      "[15,    96] loss: 1.032\n",
      "Starting Epoch:  15\n",
      "[16,    96] loss: 0.981\n",
      "Starting Epoch:  16\n",
      "[17,    96] loss: 0.981\n",
      "Starting Epoch:  17\n",
      "[18,    96] loss: 0.941\n",
      "Starting Epoch:  18\n",
      "[19,    96] loss: 0.899\n",
      "Starting Epoch:  19\n",
      "[20,    96] loss: 0.876\n",
      "Starting Epoch:  20\n",
      "[21,    96] loss: 0.826\n",
      "Starting Epoch:  21\n",
      "[22,    96] loss: 0.778\n",
      "Starting Epoch:  22\n",
      "[23,    96] loss: 0.738\n",
      "Starting Epoch:  23\n",
      "[24,    96] loss: 0.694\n",
      "Starting Epoch:  24\n",
      "[25,    96] loss: 0.696\n",
      "Starting Epoch:  25\n",
      "[26,    96] loss: 0.698\n",
      "Starting Epoch:  26\n",
      "[27,    96] loss: 0.628\n",
      "Starting Epoch:  27\n",
      "[28,    96] loss: 0.611\n",
      "Starting Epoch:  28\n",
      "[29,    96] loss: 0.636\n",
      "Starting Epoch:  29\n",
      "[30,    96] loss: 0.597\n",
      "Starting Epoch:  30\n",
      "[31,    96] loss: 0.486\n",
      "Starting Epoch:  31\n",
      "[32,    96] loss: 0.517\n",
      "Starting Epoch:  32\n",
      "[33,    96] loss: 0.499\n",
      "Starting Epoch:  33\n",
      "[34,    96] loss: 0.462\n",
      "Starting Epoch:  34\n",
      "[35,    96] loss: 0.500\n",
      "Starting Epoch:  35\n",
      "[36,    96] loss: 0.459\n",
      "Starting Epoch:  36\n",
      "[37,    96] loss: 0.400\n",
      "Starting Epoch:  37\n",
      "[38,    96] loss: 0.401\n",
      "Starting Epoch:  38\n",
      "[39,    96] loss: 0.386\n",
      "Starting Epoch:  39\n",
      "[40,    96] loss: 0.385\n",
      "Starting Epoch:  40\n",
      "[41,    96] loss: 0.339\n",
      "Starting Epoch:  41\n",
      "[42,    96] loss: 0.332\n",
      "Starting Epoch:  42\n",
      "[43,    96] loss: 0.376\n",
      "Starting Epoch:  43\n",
      "[44,    96] loss: 0.354\n",
      "Starting Epoch:  44\n",
      "[45,    96] loss: 0.283\n",
      "Starting Epoch:  45\n",
      "[46,    96] loss: 0.317\n",
      "Starting Epoch:  46\n",
      "[47,    96] loss: 0.312\n",
      "Starting Epoch:  47\n",
      "[48,    96] loss: 0.270\n",
      "Starting Epoch:  48\n",
      "[49,    96] loss: 0.294\n",
      "Starting Epoch:  49\n",
      "[50,    96] loss: 0.265\n",
      "Starting Epoch:  50\n",
      "[51,    96] loss: 0.271\n",
      "Starting Epoch:  51\n",
      "[52,    96] loss: 0.293\n",
      "Starting Epoch:  52\n",
      "[53,    96] loss: 0.295\n",
      "Starting Epoch:  53\n",
      "[54,    96] loss: 0.265\n",
      "Starting Epoch:  54\n",
      "[55,    96] loss: 0.238\n",
      "Starting Epoch:  55\n",
      "[56,    96] loss: 0.216\n",
      "Starting Epoch:  56\n",
      "[57,    96] loss: 0.285\n",
      "Starting Epoch:  57\n",
      "[58,    96] loss: 0.275\n",
      "Starting Epoch:  58\n",
      "[59,    96] loss: 0.203\n",
      "Starting Epoch:  59\n",
      "[60,    96] loss: 0.220\n",
      "Starting Epoch:  60\n",
      "[61,    96] loss: 0.202\n",
      "Starting Epoch:  61\n",
      "[62,    96] loss: 0.237\n",
      "Starting Epoch:  62\n",
      "[63,    96] loss: 0.202\n",
      "Starting Epoch:  63\n",
      "[64,    96] loss: 0.222\n",
      "Starting Epoch:  64\n",
      "[65,    96] loss: 0.209\n",
      "Starting Epoch:  65\n",
      "[66,    96] loss: 0.194\n",
      "Starting Epoch:  66\n",
      "[67,    96] loss: 0.188\n",
      "Starting Epoch:  67\n",
      "[68,    96] loss: 0.201\n",
      "Starting Epoch:  68\n",
      "[69,    96] loss: 0.155\n",
      "Starting Epoch:  69\n",
      "[70,    96] loss: 0.170\n",
      "Starting Epoch:  70\n",
      "[71,    96] loss: 0.193\n",
      "Starting Epoch:  71\n",
      "[72,    96] loss: 0.211\n",
      "Starting Epoch:  72\n",
      "[73,    96] loss: 0.167\n",
      "Starting Epoch:  73\n",
      "[74,    96] loss: 0.174\n",
      "Starting Epoch:  74\n",
      "[75,    96] loss: 0.180\n",
      "Starting Epoch:  75\n",
      "[76,    96] loss: 0.164\n",
      "Starting Epoch:  76\n",
      "[77,    96] loss: 0.147\n",
      "Starting Epoch:  77\n",
      "[78,    96] loss: 0.139\n",
      "Starting Epoch:  78\n",
      "[79,    96] loss: 0.164\n",
      "Starting Epoch:  79\n",
      "[80,    96] loss: 0.160\n",
      "Starting Epoch:  80\n",
      "[81,    96] loss: 0.180\n",
      "Starting Epoch:  81\n",
      "[82,    96] loss: 0.170\n",
      "Starting Epoch:  82\n",
      "[83,    96] loss: 0.131\n",
      "Starting Epoch:  83\n",
      "[84,    96] loss: 0.135\n",
      "Starting Epoch:  84\n",
      "[85,    96] loss: 0.141\n",
      "Starting Epoch:  85\n",
      "[86,    96] loss: 0.136\n",
      "Starting Epoch:  86\n",
      "[87,    96] loss: 0.152\n",
      "Starting Epoch:  87\n",
      "[88,    96] loss: 0.142\n",
      "Starting Epoch:  88\n",
      "[89,    96] loss: 0.171\n",
      "Starting Epoch:  89\n",
      "[90,    96] loss: 0.168\n",
      "Starting Epoch:  90\n",
      "[91,    96] loss: 0.124\n",
      "Starting Epoch:  91\n",
      "[92,    96] loss: 0.109\n",
      "Starting Epoch:  92\n",
      "[93,    96] loss: 0.135\n",
      "Starting Epoch:  93\n",
      "[94,    96] loss: 0.142\n",
      "Starting Epoch:  94\n",
      "[95,    96] loss: 0.138\n",
      "Starting Epoch:  95\n",
      "[96,    96] loss: 0.114\n",
      "Starting Epoch:  96\n",
      "[97,    96] loss: 0.126\n",
      "Starting Epoch:  97\n",
      "[98,    96] loss: 0.116\n",
      "Starting Epoch:  98\n",
      "[99,    96] loss: 0.139\n",
      "Starting Epoch:  99\n",
      "[100,    96] loss: 0.125\n",
      "Starting Epoch:  100\n",
      "[101,    96] loss: 0.119\n",
      "Starting Epoch:  101\n",
      "[102,    96] loss: 0.127\n",
      "Nuevo modelo!\n",
      "Starting Epoch:  102\n",
      "[103,    96] loss: 0.131\n",
      "Nuevo modelo!\n",
      "Starting Epoch:  103\n",
      "[104,    96] loss: 0.089\n",
      "Starting Epoch:  104\n",
      "[105,    96] loss: 0.074\n",
      "Nuevo modelo!\n",
      "Starting Epoch:  105\n",
      "[106,    96] loss: 0.136\n",
      "Starting Epoch:  106\n",
      "[107,    96] loss: 0.130\n",
      "Starting Epoch:  107\n",
      "[108,    96] loss: 0.111\n",
      "Starting Epoch:  108\n",
      "[109,    96] loss: 0.091\n",
      "Starting Epoch:  109\n",
      "[110,    96] loss: 0.077\n",
      "Starting Epoch:  110\n",
      "[111,    96] loss: 0.103\n",
      "Starting Epoch:  111\n",
      "[112,    96] loss: 0.104\n",
      "Starting Epoch:  112\n",
      "[113,    96] loss: 0.082\n",
      "Starting Epoch:  113\n",
      "[114,    96] loss: 0.107\n",
      "Starting Epoch:  114\n",
      "[115,    96] loss: 0.127\n",
      "Starting Epoch:  115\n",
      "[116,    96] loss: 0.088\n",
      "Starting Epoch:  116\n",
      "[117,    96] loss: 0.106\n",
      "Starting Epoch:  117\n",
      "[118,    96] loss: 0.132\n",
      "Starting Epoch:  118\n",
      "[119,    96] loss: 0.123\n",
      "Starting Epoch:  119\n",
      "[120,    96] loss: 0.077\n",
      "Starting Epoch:  120\n",
      "[121,    96] loss: 0.070\n",
      "Starting Epoch:  121\n",
      "[122,    96] loss: 0.101\n",
      "Starting Epoch:  122\n",
      "[123,    96] loss: 0.100\n",
      "Starting Epoch:  123\n",
      "[124,    96] loss: 0.138\n",
      "Starting Epoch:  124\n",
      "[125,    96] loss: 0.104\n",
      "Starting Epoch:  125\n",
      "[126,    96] loss: 0.104\n",
      "Starting Epoch:  126\n",
      "[127,    96] loss: 0.077\n",
      "Starting Epoch:  127\n",
      "[128,    96] loss: 0.075\n",
      "Starting Epoch:  128\n",
      "[129,    96] loss: 0.085\n",
      "Starting Epoch:  129\n",
      "[130,    96] loss: 0.076\n",
      "Starting Epoch:  130\n",
      "[131,    96] loss: 0.088\n",
      "Starting Epoch:  131\n",
      "[132,    96] loss: 0.070\n",
      "Starting Epoch:  132\n",
      "[133,    96] loss: 0.067\n",
      "Starting Epoch:  133\n",
      "[134,    96] loss: 0.082\n",
      "Starting Epoch:  134\n",
      "[135,    96] loss: 0.090\n",
      "Starting Epoch:  135\n",
      "[136,    96] loss: 0.089\n",
      "Starting Epoch:  136\n",
      "[137,    96] loss: 0.082\n",
      "Starting Epoch:  137\n",
      "[138,    96] loss: 0.096\n",
      "Starting Epoch:  138\n",
      "[139,    96] loss: 0.101\n",
      "Starting Epoch:  139\n",
      "[140,    96] loss: 0.093\n",
      "Starting Epoch:  140\n",
      "[141,    96] loss: 0.092\n",
      "Starting Epoch:  141\n",
      "[142,    96] loss: 0.067\n",
      "Starting Epoch:  142\n",
      "[143,    96] loss: 0.088\n",
      "Starting Epoch:  143\n",
      "[144,    96] loss: 0.092\n",
      "Starting Epoch:  144\n",
      "[145,    96] loss: 0.090\n",
      "Starting Epoch:  145\n",
      "[146,    96] loss: 0.102\n",
      "Starting Epoch:  146\n",
      "[147,    96] loss: 0.059\n",
      "Starting Epoch:  147\n",
      "[148,    96] loss: 0.049\n",
      "Starting Epoch:  148\n",
      "[149,    96] loss: 0.043\n",
      "Starting Epoch:  149\n",
      "[150,    96] loss: 0.061\n",
      "Starting Epoch:  150\n",
      "[151,    96] loss: 0.052\n",
      "Starting Epoch:  151\n",
      "[152,    96] loss: 0.058\n",
      "Starting Epoch:  152\n",
      "[153,    96] loss: 0.109\n",
      "Starting Epoch:  153\n",
      "[154,    96] loss: 0.069\n",
      "Starting Epoch:  154\n",
      "[155,    96] loss: 0.063\n",
      "Starting Epoch:  155\n",
      "[156,    96] loss: 0.078\n",
      "Starting Epoch:  156\n",
      "[157,    96] loss: 0.083\n",
      "Starting Epoch:  157\n",
      "[158,    96] loss: 0.072\n",
      "Starting Epoch:  158\n",
      "[159,    96] loss: 0.096\n",
      "Starting Epoch:  159\n",
      "[160,    96] loss: 0.083\n",
      "Starting Epoch:  160\n",
      "[161,    96] loss: 0.072\n",
      "Nuevo modelo!\n",
      "Starting Epoch:  161\n",
      "[162,    96] loss: 0.060\n",
      "Starting Epoch:  162\n",
      "[163,    96] loss: 0.054\n",
      "Starting Epoch:  163\n",
      "[164,    96] loss: 0.053\n",
      "Starting Epoch:  164\n",
      "[165,    96] loss: 0.057\n",
      "Starting Epoch:  165\n",
      "[166,    96] loss: 0.065\n",
      "Starting Epoch:  166\n",
      "[167,    96] loss: 0.072\n",
      "Starting Epoch:  167\n",
      "[168,    96] loss: 0.070\n",
      "Starting Epoch:  168\n",
      "[169,    96] loss: 0.051\n",
      "Starting Epoch:  169\n",
      "[170,    96] loss: 0.036\n",
      "Starting Epoch:  170\n",
      "[171,    96] loss: 0.057\n",
      "Starting Epoch:  171\n",
      "[172,    96] loss: 0.073\n",
      "Starting Epoch:  172\n",
      "[173,    96] loss: 0.104\n",
      "Starting Epoch:  173\n",
      "[174,    96] loss: 0.068\n",
      "Starting Epoch:  174\n",
      "[175,    96] loss: 0.078\n",
      "Starting Epoch:  175\n",
      "[176,    96] loss: 0.043\n",
      "Starting Epoch:  176\n",
      "[177,    96] loss: 0.050\n",
      "Starting Epoch:  177\n",
      "[178,    96] loss: 0.051\n",
      "Starting Epoch:  178\n",
      "[179,    96] loss: 0.053\n",
      "Starting Epoch:  179\n",
      "[180,    96] loss: 0.079\n",
      "Starting Epoch:  180\n",
      "[181,    96] loss: 0.092\n",
      "Starting Epoch:  181\n",
      "[182,    96] loss: 0.064\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch:  182\n",
      "[183,    96] loss: 0.072\n",
      "Starting Epoch:  183\n",
      "[184,    96] loss: 0.059\n",
      "Starting Epoch:  184\n",
      "[185,    96] loss: 0.067\n",
      "Starting Epoch:  185\n",
      "[186,    96] loss: 0.034\n",
      "Starting Epoch:  186\n",
      "[187,    96] loss: 0.045\n",
      "Starting Epoch:  187\n",
      "[188,    96] loss: 0.050\n",
      "Starting Epoch:  188\n",
      "[189,    96] loss: 0.051\n",
      "Starting Epoch:  189\n",
      "[190,    96] loss: 0.059\n",
      "Starting Epoch:  190\n",
      "[191,    96] loss: 0.071\n",
      "Starting Epoch:  191\n",
      "[192,    96] loss: 0.058\n",
      "Starting Epoch:  192\n",
      "[193,    96] loss: 0.061\n",
      "Starting Epoch:  193\n",
      "[194,    96] loss: 0.060\n",
      "Starting Epoch:  194\n",
      "[195,    96] loss: 0.049\n",
      "Starting Epoch:  195\n",
      "[196,    96] loss: 0.042\n",
      "Starting Epoch:  196\n",
      "[197,    96] loss: 0.065\n",
      "Starting Epoch:  197\n",
      "[198,    96] loss: 0.075\n",
      "Starting Epoch:  198\n",
      "[199,    96] loss: 0.068\n",
      "Starting Epoch:  199\n",
      "[200,    96] loss: 0.063\n",
      "Starting Epoch:  200\n",
      "[201,    96] loss: 0.047\n",
      "Starting Epoch:  201\n",
      "[202,    96] loss: 0.035\n",
      "Starting Epoch:  202\n",
      "[203,    96] loss: 0.029\n",
      "Starting Epoch:  203\n",
      "[204,    96] loss: 0.054\n",
      "Starting Epoch:  204\n",
      "[205,    96] loss: 0.044\n",
      "Starting Epoch:  205\n",
      "[206,    96] loss: 0.049\n",
      "Starting Epoch:  206\n",
      "[207,    96] loss: 0.062\n",
      "Starting Epoch:  207\n",
      "[208,    96] loss: 0.050\n",
      "Starting Epoch:  208\n",
      "[209,    96] loss: 0.070\n",
      "Starting Epoch:  209\n",
      "[210,    96] loss: 0.069\n",
      "Starting Epoch:  210\n",
      "[211,    96] loss: 0.054\n",
      "Starting Epoch:  211\n",
      "[212,    96] loss: 0.044\n",
      "Starting Epoch:  212\n",
      "[213,    96] loss: 0.048\n",
      "Starting Epoch:  213\n",
      "[214,    96] loss: 0.031\n",
      "Starting Epoch:  214\n",
      "[215,    96] loss: 0.034\n",
      "Starting Epoch:  215\n",
      "[216,    96] loss: 0.049\n",
      "Starting Epoch:  216\n",
      "[217,    96] loss: 0.043\n",
      "Starting Epoch:  217\n",
      "[218,    96] loss: 0.052\n",
      "Starting Epoch:  218\n",
      "[219,    96] loss: 0.072\n",
      "Starting Epoch:  219\n",
      "[220,    96] loss: 0.052\n",
      "Starting Epoch:  220\n",
      "[221,    96] loss: 0.048\n",
      "Starting Epoch:  221\n",
      "[222,    96] loss: 0.038\n",
      "Starting Epoch:  222\n",
      "[223,    96] loss: 0.046\n",
      "Starting Epoch:  223\n",
      "[224,    96] loss: 0.040\n",
      "Starting Epoch:  224\n",
      "[225,    96] loss: 0.047\n",
      "Starting Epoch:  225\n",
      "[226,    96] loss: 0.040\n",
      "Starting Epoch:  226\n",
      "[227,    96] loss: 0.044\n",
      "Starting Epoch:  227\n",
      "[228,    96] loss: 0.049\n",
      "Starting Epoch:  228\n",
      "[229,    96] loss: 0.046\n",
      "Starting Epoch:  229\n",
      "[230,    96] loss: 0.052\n",
      "Starting Epoch:  230\n",
      "[231,    96] loss: 0.060\n",
      "Starting Epoch:  231\n",
      "[232,    96] loss: 0.054\n",
      "Starting Epoch:  232\n",
      "[233,    96] loss: 0.067\n",
      "Starting Epoch:  233\n",
      "[234,    96] loss: 0.033\n",
      "Starting Epoch:  234\n",
      "[235,    96] loss: 0.054\n",
      "Starting Epoch:  235\n",
      "[236,    96] loss: 0.035\n",
      "Starting Epoch:  236\n",
      "[237,    96] loss: 0.035\n",
      "Starting Epoch:  237\n",
      "[238,    96] loss: 0.056\n",
      "Starting Epoch:  238\n",
      "[239,    96] loss: 0.066\n",
      "Starting Epoch:  239\n",
      "[240,    96] loss: 0.059\n",
      "Starting Epoch:  240\n",
      "[241,    96] loss: 0.042\n",
      "Nuevo modelo!\n",
      "Starting Epoch:  241\n",
      "[242,    96] loss: 0.043\n",
      "Starting Epoch:  242\n",
      "[243,    96] loss: 0.031\n",
      "Starting Epoch:  243\n",
      "[244,    96] loss: 0.046\n",
      "Starting Epoch:  244\n",
      "[245,    96] loss: 0.032\n",
      "Starting Epoch:  245\n",
      "[246,    96] loss: 0.035\n",
      "Starting Epoch:  246\n",
      "[247,    96] loss: 0.030\n",
      "Starting Epoch:  247\n",
      "[248,    96] loss: 0.032\n",
      "Starting Epoch:  248\n",
      "[249,    96] loss: 0.034\n",
      "Starting Epoch:  249\n",
      "[250,    96] loss: 0.048\n",
      "Starting Epoch:  250\n",
      "[251,    96] loss: 0.041\n",
      "Starting Epoch:  251\n",
      "[252,    96] loss: 0.034\n",
      "Starting Epoch:  252\n",
      "[253,    96] loss: 0.034\n",
      "Starting Epoch:  253\n",
      "[254,    96] loss: 0.051\n",
      "Starting Epoch:  254\n",
      "[255,    96] loss: 0.051\n",
      "Starting Epoch:  255\n",
      "[256,    96] loss: 0.054\n",
      "Starting Epoch:  256\n",
      "[257,    96] loss: 0.031\n",
      "Nuevo modelo!\n",
      "Starting Epoch:  257\n",
      "[258,    96] loss: 0.027\n",
      "Starting Epoch:  258\n",
      "[259,    96] loss: 0.037\n",
      "Starting Epoch:  259\n",
      "[260,    96] loss: 0.043\n",
      "Starting Epoch:  260\n",
      "[261,    96] loss: 0.038\n",
      "Starting Epoch:  261\n",
      "[262,    96] loss: 0.033\n",
      "Starting Epoch:  262\n",
      "[263,    96] loss: 0.015\n",
      "Starting Epoch:  263\n",
      "[264,    96] loss: 0.048\n",
      "Starting Epoch:  264\n",
      "[265,    96] loss: 0.046\n",
      "Starting Epoch:  265\n",
      "[266,    96] loss: 0.052\n",
      "Starting Epoch:  266\n",
      "[267,    96] loss: 0.055\n",
      "Starting Epoch:  267\n",
      "[268,    96] loss: 0.052\n",
      "Starting Epoch:  268\n",
      "[269,    96] loss: 0.041\n",
      "Starting Epoch:  269\n",
      "[270,    96] loss: 0.042\n",
      "Starting Epoch:  270\n",
      "[271,    96] loss: 0.048\n",
      "Starting Epoch:  271\n",
      "[272,    96] loss: 0.038\n",
      "Starting Epoch:  272\n",
      "[273,    96] loss: 0.029\n",
      "Starting Epoch:  273\n",
      "[274,    96] loss: 0.030\n",
      "Starting Epoch:  274\n",
      "[275,    96] loss: 0.022\n",
      "Starting Epoch:  275\n",
      "[276,    96] loss: 0.029\n",
      "Starting Epoch:  276\n",
      "[277,    96] loss: 0.038\n",
      "Starting Epoch:  277\n",
      "[278,    96] loss: 0.039\n",
      "Starting Epoch:  278\n",
      "[279,    96] loss: 0.026\n",
      "Starting Epoch:  279\n",
      "[280,    96] loss: 0.049\n",
      "Starting Epoch:  280\n",
      "[281,    96] loss: 0.053\n",
      "Starting Epoch:  281\n",
      "[282,    96] loss: 0.029\n",
      "Starting Epoch:  282\n",
      "[283,    96] loss: 0.027\n",
      "Starting Epoch:  283\n",
      "[284,    96] loss: 0.031\n",
      "Starting Epoch:  284\n",
      "[285,    96] loss: 0.050\n",
      "Starting Epoch:  285\n",
      "[286,    96] loss: 0.043\n",
      "Starting Epoch:  286\n",
      "[287,    96] loss: 0.033\n",
      "Starting Epoch:  287\n",
      "[288,    96] loss: 0.043\n",
      "Starting Epoch:  288\n",
      "[289,    96] loss: 0.068\n",
      "Starting Epoch:  289\n",
      "[290,    96] loss: 0.034\n",
      "Starting Epoch:  290\n",
      "[291,    96] loss: 0.024\n",
      "Starting Epoch:  291\n",
      "[292,    96] loss: 0.023\n",
      "Starting Epoch:  292\n",
      "[293,    96] loss: 0.034\n",
      "Starting Epoch:  293\n",
      "[294,    96] loss: 0.028\n",
      "Starting Epoch:  294\n",
      "[295,    96] loss: 0.023\n",
      "Starting Epoch:  295\n",
      "[296,    96] loss: 0.018\n",
      "Starting Epoch:  296\n",
      "[297,    96] loss: 0.035\n",
      "Starting Epoch:  297\n",
      "[298,    96] loss: 0.027\n",
      "Starting Epoch:  298\n",
      "[299,    96] loss: 0.030\n",
      "Starting Epoch:  299\n",
      "[300,    96] loss: 0.057\n",
      "Starting Epoch:  300\n",
      "[301,    96] loss: 0.046\n",
      "Starting Epoch:  301\n",
      "[302,    96] loss: 0.040\n",
      "Starting Epoch:  302\n",
      "[303,    96] loss: 0.030\n",
      "Starting Epoch:  303\n",
      "[304,    96] loss: 0.025\n",
      "Starting Epoch:  304\n",
      "[305,    96] loss: 0.030\n",
      "Starting Epoch:  305\n",
      "[306,    96] loss: 0.026\n",
      "Starting Epoch:  306\n",
      "[307,    96] loss: 0.051\n",
      "Starting Epoch:  307\n",
      "[308,    96] loss: 0.038\n",
      "Starting Epoch:  308\n",
      "[309,    96] loss: 0.037\n",
      "Starting Epoch:  309\n",
      "[310,    96] loss: 0.036\n",
      "Starting Epoch:  310\n",
      "[311,    96] loss: 0.013\n",
      "Starting Epoch:  311\n",
      "[312,    96] loss: 0.009\n",
      "Starting Epoch:  312\n",
      "[313,    96] loss: 0.017\n",
      "Starting Epoch:  313\n",
      "[314,    96] loss: 0.035\n",
      "Starting Epoch:  314\n",
      "[315,    96] loss: 0.091\n",
      "Starting Epoch:  315\n",
      "[316,    96] loss: 0.047\n",
      "Starting Epoch:  316\n",
      "[317,    96] loss: 0.030\n",
      "Starting Epoch:  317\n",
      "[318,    96] loss: 0.030\n",
      "Starting Epoch:  318\n",
      "[319,    96] loss: 0.021\n",
      "Starting Epoch:  319\n",
      "[320,    96] loss: 0.029\n",
      "Nuevo modelo!\n",
      "Starting Epoch:  320\n",
      "[321,    96] loss: 0.025\n",
      "Starting Epoch:  321\n",
      "[322,    96] loss: 0.035\n",
      "Starting Epoch:  322\n",
      "[323,    96] loss: 0.030\n",
      "Starting Epoch:  323\n",
      "[324,    96] loss: 0.037\n",
      "Starting Epoch:  324\n",
      "[325,    96] loss: 0.020\n",
      "Starting Epoch:  325\n",
      "[326,    96] loss: 0.017\n",
      "Starting Epoch:  326\n",
      "[327,    96] loss: 0.022\n",
      "Starting Epoch:  327\n",
      "[328,    96] loss: 0.025\n",
      "Starting Epoch:  328\n",
      "[329,    96] loss: 0.022\n",
      "Starting Epoch:  329\n",
      "[330,    96] loss: 0.022\n",
      "Starting Epoch:  330\n",
      "[331,    96] loss: 0.036\n",
      "Starting Epoch:  331\n",
      "[332,    96] loss: 0.039\n",
      "Starting Epoch:  332\n",
      "[333,    96] loss: 0.034\n",
      "Starting Epoch:  333\n",
      "[334,    96] loss: 0.030\n",
      "Starting Epoch:  334\n",
      "[335,    96] loss: 0.030\n",
      "Starting Epoch:  335\n",
      "[336,    96] loss: 0.042\n",
      "Starting Epoch:  336\n",
      "[337,    96] loss: 0.035\n",
      "Starting Epoch:  337\n",
      "[338,    96] loss: 0.026\n",
      "Starting Epoch:  338\n",
      "[339,    96] loss: 0.031\n",
      "Starting Epoch:  339\n",
      "[340,    96] loss: 0.017\n",
      "Starting Epoch:  340\n",
      "[341,    96] loss: 0.015\n",
      "Starting Epoch:  341\n",
      "[342,    96] loss: 0.020\n",
      "Starting Epoch:  342\n",
      "[343,    96] loss: 0.035\n",
      "Starting Epoch:  343\n",
      "[344,    96] loss: 0.043\n",
      "Starting Epoch:  344\n",
      "[345,    96] loss: 0.058\n",
      "Starting Epoch:  345\n",
      "[346,    96] loss: 0.047\n",
      "Starting Epoch:  346\n",
      "[347,    96] loss: 0.028\n",
      "Starting Epoch:  347\n",
      "[348,    96] loss: 0.026\n",
      "Starting Epoch:  348\n",
      "[349,    96] loss: 0.015\n",
      "Starting Epoch:  349\n",
      "[350,    96] loss: 0.031\n",
      "Starting Epoch:  350\n",
      "[351,    96] loss: 0.017\n",
      "Starting Epoch:  351\n",
      "[352,    96] loss: 0.014\n",
      "Starting Epoch:  352\n",
      "[353,    96] loss: 0.020\n",
      "Starting Epoch:  353\n",
      "[354,    96] loss: 0.037\n",
      "Starting Epoch:  354\n",
      "[355,    96] loss: 0.024\n",
      "Starting Epoch:  355\n",
      "[356,    96] loss: 0.021\n",
      "Starting Epoch:  356\n",
      "[357,    96] loss: 0.034\n",
      "Starting Epoch:  357\n",
      "[358,    96] loss: 0.039\n",
      "Starting Epoch:  358\n",
      "[359,    96] loss: 0.028\n",
      "Starting Epoch:  359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[360,    96] loss: 0.017\n",
      "Starting Epoch:  360\n",
      "[361,    96] loss: 0.020\n",
      "Starting Epoch:  361\n",
      "[362,    96] loss: 0.024\n",
      "Starting Epoch:  362\n",
      "[363,    96] loss: 0.022\n",
      "Starting Epoch:  363\n",
      "[364,    96] loss: 0.017\n",
      "Starting Epoch:  364\n",
      "[365,    96] loss: 0.014\n",
      "Starting Epoch:  365\n",
      "[366,    96] loss: 0.025\n",
      "Starting Epoch:  366\n",
      "[367,    96] loss: 0.033\n",
      "Starting Epoch:  367\n",
      "[368,    96] loss: 0.032\n",
      "Starting Epoch:  368\n",
      "[369,    96] loss: 0.032\n",
      "Starting Epoch:  369\n",
      "[370,    96] loss: 0.066\n",
      "Starting Epoch:  370\n",
      "[371,    96] loss: 0.055\n",
      "Starting Epoch:  371\n",
      "[372,    96] loss: 0.030\n",
      "Starting Epoch:  372\n",
      "[373,    96] loss: 0.019\n",
      "Starting Epoch:  373\n",
      "[374,    96] loss: 0.030\n",
      "Starting Epoch:  374\n",
      "[375,    96] loss: 0.035\n",
      "Starting Epoch:  375\n",
      "[376,    96] loss: 0.018\n",
      "Starting Epoch:  376\n",
      "[377,    96] loss: 0.016\n",
      "Starting Epoch:  377\n",
      "[378,    96] loss: 0.011\n",
      "Starting Epoch:  378\n",
      "[379,    96] loss: 0.015\n",
      "Starting Epoch:  379\n",
      "[380,    96] loss: 0.038\n",
      "Starting Epoch:  380\n",
      "[381,    96] loss: 0.022\n",
      "Starting Epoch:  381\n",
      "[382,    96] loss: 0.029\n",
      "Starting Epoch:  382\n",
      "[383,    96] loss: 0.036\n",
      "Starting Epoch:  383\n",
      "[384,    96] loss: 0.035\n",
      "Starting Epoch:  384\n",
      "[385,    96] loss: 0.024\n",
      "Starting Epoch:  385\n",
      "[386,    96] loss: 0.015\n",
      "Starting Epoch:  386\n",
      "[387,    96] loss: 0.024\n",
      "Starting Epoch:  387\n",
      "[388,    96] loss: 0.028\n",
      "Starting Epoch:  388\n",
      "[389,    96] loss: 0.031\n",
      "Starting Epoch:  389\n",
      "[390,    96] loss: 0.034\n",
      "Starting Epoch:  390\n",
      "[391,    96] loss: 0.035\n",
      "Starting Epoch:  391\n",
      "[392,    96] loss: 0.025\n",
      "Starting Epoch:  392\n",
      "[393,    96] loss: 0.022\n",
      "Starting Epoch:  393\n",
      "[394,    96] loss: 0.014\n",
      "Starting Epoch:  394\n",
      "[395,    96] loss: 0.017\n",
      "Starting Epoch:  395\n",
      "[396,    96] loss: 0.018\n",
      "Starting Epoch:  396\n",
      "[397,    96] loss: 0.026\n",
      "Starting Epoch:  397\n",
      "[398,    96] loss: 0.013\n",
      "Starting Epoch:  398\n",
      "[399,    96] loss: 0.019\n",
      "Starting Epoch:  399\n",
      "[400,    96] loss: 0.025\n",
      "Starting Epoch:  400\n",
      "[401,    96] loss: 0.020\n",
      "Starting Epoch:  401\n",
      "[402,    96] loss: 0.024\n",
      "Starting Epoch:  402\n",
      "[403,    96] loss: 0.024\n",
      "Starting Epoch:  403\n",
      "[404,    96] loss: 0.045\n",
      "Starting Epoch:  404\n",
      "[405,    96] loss: 0.037\n",
      "Starting Epoch:  405\n",
      "[406,    96] loss: 0.036\n",
      "Starting Epoch:  406\n",
      "[407,    96] loss: 0.025\n",
      "Starting Epoch:  407\n",
      "[408,    96] loss: 0.030\n",
      "Starting Epoch:  408\n",
      "[409,    96] loss: 0.023\n",
      "Starting Epoch:  409\n",
      "[410,    96] loss: 0.020\n",
      "Nuevo modelo!: WOW ./model_test_409.pth\n",
      "Starting Epoch:  410\n",
      "[411,    96] loss: 0.021\n",
      "Starting Epoch:  411\n",
      "[412,    96] loss: 0.011\n",
      "Starting Epoch:  412\n",
      "[413,    96] loss: 0.019\n",
      "Starting Epoch:  413\n",
      "[414,    96] loss: 0.028\n",
      "Starting Epoch:  414\n",
      "[415,    96] loss: 0.010\n",
      "Starting Epoch:  415\n",
      "[416,    96] loss: 0.017\n",
      "Starting Epoch:  416\n",
      "[417,    96] loss: 0.016\n",
      "Starting Epoch:  417\n",
      "[418,    96] loss: 0.026\n",
      "Starting Epoch:  418\n",
      "[419,    96] loss: 0.036\n",
      "Starting Epoch:  419\n",
      "[420,    96] loss: 0.031\n",
      "Starting Epoch:  420\n",
      "[421,    96] loss: 0.037\n",
      "Starting Epoch:  421\n",
      "[422,    96] loss: 0.031\n",
      "Starting Epoch:  422\n",
      "[423,    96] loss: 0.028\n",
      "Starting Epoch:  423\n",
      "[424,    96] loss: 0.021\n",
      "Starting Epoch:  424\n",
      "[425,    96] loss: 0.017\n",
      "Starting Epoch:  425\n",
      "[426,    96] loss: 0.022\n",
      "Starting Epoch:  426\n",
      "[427,    96] loss: 0.015\n",
      "Starting Epoch:  427\n",
      "[428,    96] loss: 0.016\n",
      "Starting Epoch:  428\n",
      "[429,    96] loss: 0.028\n",
      "Starting Epoch:  429\n",
      "[430,    96] loss: 0.026\n",
      "Starting Epoch:  430\n",
      "[431,    96] loss: 0.022\n",
      "Starting Epoch:  431\n",
      "[432,    96] loss: 0.025\n",
      "Starting Epoch:  432\n",
      "[433,    96] loss: 0.032\n",
      "Starting Epoch:  433\n",
      "[434,    96] loss: 0.028\n",
      "Starting Epoch:  434\n",
      "[435,    96] loss: 0.032\n",
      "Starting Epoch:  435\n",
      "[436,    96] loss: 0.028\n",
      "Starting Epoch:  436\n",
      "[437,    96] loss: 0.025\n",
      "Nuevo modelo!: WOW ./model_test_436.pth\n",
      "Starting Epoch:  437\n",
      "[438,    96] loss: 0.017\n",
      "Starting Epoch:  438\n",
      "[439,    96] loss: 0.022\n",
      "Starting Epoch:  439\n",
      "[440,    96] loss: 0.034\n",
      "Starting Epoch:  440\n",
      "[441,    96] loss: 0.035\n",
      "Starting Epoch:  441\n",
      "[442,    96] loss: 0.024\n",
      "Starting Epoch:  442\n",
      "[443,    96] loss: 0.016\n",
      "Starting Epoch:  443\n",
      "[444,    96] loss: 0.009\n",
      "Starting Epoch:  444\n",
      "[445,    96] loss: 0.012\n",
      "Starting Epoch:  445\n",
      "[446,    96] loss: 0.008\n",
      "Starting Epoch:  446\n",
      "[447,    96] loss: 0.006\n",
      "Starting Epoch:  447\n",
      "[448,    96] loss: 0.008\n",
      "Starting Epoch:  448\n",
      "[449,    96] loss: 0.015\n",
      "Starting Epoch:  449\n",
      "[450,    96] loss: 0.008\n",
      "Starting Epoch:  450\n",
      "[451,    96] loss: 0.012\n",
      "Starting Epoch:  451\n",
      "[452,    96] loss: 0.026\n",
      "Starting Epoch:  452\n",
      "[453,    96] loss: 0.035\n",
      "Starting Epoch:  453\n",
      "[454,    96] loss: 0.013\n",
      "Starting Epoch:  454\n",
      "[455,    96] loss: 0.015\n",
      "Starting Epoch:  455\n",
      "[456,    96] loss: 0.019\n",
      "Starting Epoch:  456\n",
      "[457,    96] loss: 0.020\n",
      "Starting Epoch:  457\n",
      "[458,    96] loss: 0.017\n",
      "Starting Epoch:  458\n",
      "[459,    96] loss: 0.026\n",
      "Starting Epoch:  459\n",
      "[460,    96] loss: 0.045\n",
      "Starting Epoch:  460\n",
      "[461,    96] loss: 0.038\n",
      "Starting Epoch:  461\n",
      "[462,    96] loss: 0.020\n",
      "Starting Epoch:  462\n",
      "[463,    96] loss: 0.015\n",
      "Starting Epoch:  463\n",
      "[464,    96] loss: 0.012\n",
      "Starting Epoch:  464\n",
      "[465,    96] loss: 0.011\n",
      "Starting Epoch:  465\n",
      "[466,    96] loss: 0.041\n",
      "Starting Epoch:  466\n",
      "[467,    96] loss: 0.041\n",
      "Starting Epoch:  467\n",
      "[468,    96] loss: 0.032\n",
      "Starting Epoch:  468\n",
      "[469,    96] loss: 0.014\n",
      "Starting Epoch:  469\n",
      "[470,    96] loss: 0.013\n",
      "Starting Epoch:  470\n",
      "[471,    96] loss: 0.012\n",
      "Starting Epoch:  471\n",
      "[472,    96] loss: 0.052\n",
      "Starting Epoch:  472\n",
      "[473,    96] loss: 0.011\n",
      "Starting Epoch:  473\n",
      "[474,    96] loss: 0.026\n",
      "Starting Epoch:  474\n",
      "[475,    96] loss: 0.016\n",
      "Starting Epoch:  475\n",
      "[476,    96] loss: 0.013\n",
      "Starting Epoch:  476\n",
      "[477,    96] loss: 0.012\n",
      "Starting Epoch:  477\n",
      "[478,    96] loss: 0.008\n",
      "Starting Epoch:  478\n",
      "[479,    96] loss: 0.021\n",
      "Starting Epoch:  479\n",
      "[480,    96] loss: 0.032\n",
      "Starting Epoch:  480\n",
      "[481,    96] loss: 0.043\n",
      "Starting Epoch:  481\n",
      "[482,    96] loss: 0.036\n",
      "Starting Epoch:  482\n",
      "[483,    96] loss: 0.031\n",
      "Starting Epoch:  483\n",
      "[484,    96] loss: 0.016\n",
      "Starting Epoch:  484\n",
      "[485,    96] loss: 0.008\n",
      "Starting Epoch:  485\n",
      "[486,    96] loss: 0.007\n",
      "Starting Epoch:  486\n",
      "[487,    96] loss: 0.009\n",
      "Starting Epoch:  487\n",
      "[488,    96] loss: 0.017\n",
      "Starting Epoch:  488\n",
      "[489,    96] loss: 0.026\n",
      "Starting Epoch:  489\n",
      "[490,    96] loss: 0.022\n",
      "Starting Epoch:  490\n",
      "[491,    96] loss: 0.024\n",
      "Starting Epoch:  491\n",
      "[492,    96] loss: 0.023\n",
      "Starting Epoch:  492\n",
      "[493,    96] loss: 0.022\n",
      "Starting Epoch:  493\n",
      "[494,    96] loss: 0.021\n",
      "Starting Epoch:  494\n",
      "[495,    96] loss: 0.025\n",
      "Starting Epoch:  495\n",
      "[496,    96] loss: 0.011\n",
      "Starting Epoch:  496\n",
      "[497,    96] loss: 0.016\n",
      "Starting Epoch:  497\n",
      "[498,    96] loss: 0.024\n",
      "Starting Epoch:  498\n",
      "[499,    96] loss: 0.011\n",
      "Starting Epoch:  499\n",
      "[500,    96] loss: 0.010\n",
      "Starting Epoch:  500\n",
      "[501,    96] loss: 0.017\n",
      "Starting Epoch:  501\n",
      "[502,    96] loss: 0.010\n",
      "Starting Epoch:  502\n",
      "[503,    96] loss: 0.020\n",
      "Starting Epoch:  503\n",
      "[504,    96] loss: 0.029\n",
      "Starting Epoch:  504\n",
      "[505,    96] loss: 0.033\n",
      "Starting Epoch:  505\n",
      "[506,    96] loss: 0.017\n",
      "Starting Epoch:  506\n",
      "[507,    96] loss: 0.006\n",
      "Starting Epoch:  507\n",
      "[508,    96] loss: 0.016\n",
      "Starting Epoch:  508\n",
      "[509,    96] loss: 0.036\n",
      "Starting Epoch:  509\n",
      "[510,    96] loss: 0.021\n",
      "Starting Epoch:  510\n",
      "[511,    96] loss: 0.026\n",
      "Starting Epoch:  511\n",
      "[512,    96] loss: 0.030\n",
      "Starting Epoch:  512\n",
      "[513,    96] loss: 0.018\n",
      "Starting Epoch:  513\n",
      "[514,    96] loss: 0.033\n",
      "Starting Epoch:  514\n",
      "[515,    96] loss: 0.055\n",
      "Starting Epoch:  515\n",
      "[516,    96] loss: 0.019\n",
      "Starting Epoch:  516\n",
      "[517,    96] loss: 0.022\n",
      "Starting Epoch:  517\n",
      "[518,    96] loss: 0.011\n",
      "Starting Epoch:  518\n",
      "[519,    96] loss: 0.011\n",
      "Starting Epoch:  519\n",
      "[520,    96] loss: 0.007\n",
      "Starting Epoch:  520\n",
      "[521,    96] loss: 0.005\n",
      "Starting Epoch:  521\n",
      "[522,    96] loss: 0.014\n",
      "Starting Epoch:  522\n",
      "[523,    96] loss: 0.005\n",
      "Starting Epoch:  523\n",
      "[524,    96] loss: 0.005\n",
      "Starting Epoch:  524\n",
      "[525,    96] loss: 0.010\n",
      "Starting Epoch:  525\n",
      "[526,    96] loss: 0.015\n",
      "Starting Epoch:  526\n",
      "[527,    96] loss: 0.028\n",
      "Starting Epoch:  527\n",
      "[528,    96] loss: 0.054\n",
      "Starting Epoch:  528\n",
      "[529,    96] loss: 0.025\n",
      "Starting Epoch:  529\n",
      "[530,    96] loss: 0.020\n",
      "Starting Epoch:  530\n",
      "[531,    96] loss: 0.017\n",
      "Starting Epoch:  531\n",
      "[532,    96] loss: 0.017\n",
      "Starting Epoch:  532\n",
      "[533,    96] loss: 0.029\n",
      "Starting Epoch:  533\n",
      "[534,    96] loss: 0.016\n",
      "Starting Epoch:  534\n",
      "[535,    96] loss: 0.020\n",
      "Starting Epoch:  535\n",
      "[536,    96] loss: 0.020\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch:  536\n",
      "[537,    96] loss: 0.013\n",
      "Starting Epoch:  537\n",
      "[538,    96] loss: 0.018\n",
      "Starting Epoch:  538\n",
      "[539,    96] loss: 0.031\n",
      "Starting Epoch:  539\n",
      "[540,    96] loss: 0.008\n",
      "Starting Epoch:  540\n",
      "[541,    96] loss: 0.011\n",
      "Starting Epoch:  541\n",
      "[542,    96] loss: 0.012\n",
      "Starting Epoch:  542\n",
      "[543,    96] loss: 0.008\n",
      "Starting Epoch:  543\n",
      "[544,    96] loss: 0.004\n",
      "Starting Epoch:  544\n",
      "[545,    96] loss: 0.008\n",
      "Starting Epoch:  545\n",
      "[546,    96] loss: 0.017\n",
      "Starting Epoch:  546\n",
      "[547,    96] loss: 0.012\n",
      "Starting Epoch:  547\n",
      "[548,    96] loss: 0.036\n",
      "Starting Epoch:  548\n",
      "[549,    96] loss: 0.022\n",
      "Starting Epoch:  549\n",
      "[550,    96] loss: 0.011\n",
      "Starting Epoch:  550\n",
      "[551,    96] loss: 0.006\n",
      "Starting Epoch:  551\n",
      "[552,    96] loss: 0.026\n",
      "Starting Epoch:  552\n",
      "[553,    96] loss: 0.014\n",
      "Starting Epoch:  553\n",
      "[554,    96] loss: 0.030\n",
      "Starting Epoch:  554\n",
      "[555,    96] loss: 0.017\n",
      "Starting Epoch:  555\n",
      "[556,    96] loss: 0.016\n",
      "Starting Epoch:  556\n",
      "[557,    96] loss: 0.026\n",
      "Starting Epoch:  557\n",
      "[558,    96] loss: 0.023\n",
      "Starting Epoch:  558\n",
      "[559,    96] loss: 0.026\n",
      "Starting Epoch:  559\n",
      "[560,    96] loss: 0.017\n",
      "Starting Epoch:  560\n",
      "[561,    96] loss: 0.015\n",
      "Starting Epoch:  561\n",
      "[562,    96] loss: 0.013\n",
      "Starting Epoch:  562\n",
      "[563,    96] loss: 0.012\n",
      "Starting Epoch:  563\n",
      "[564,    96] loss: 0.008\n",
      "Starting Epoch:  564\n",
      "[565,    96] loss: 0.010\n",
      "Starting Epoch:  565\n",
      "[566,    96] loss: 0.008\n",
      "Starting Epoch:  566\n",
      "[567,    96] loss: 0.040\n",
      "Starting Epoch:  567\n",
      "[568,    96] loss: 0.029\n",
      "Starting Epoch:  568\n",
      "[569,    96] loss: 0.024\n",
      "Starting Epoch:  569\n",
      "[570,    96] loss: 0.023\n",
      "Starting Epoch:  570\n",
      "[571,    96] loss: 0.029\n",
      "Starting Epoch:  571\n",
      "[572,    96] loss: 0.018\n",
      "Starting Epoch:  572\n",
      "[573,    96] loss: 0.006\n",
      "Starting Epoch:  573\n",
      "[574,    96] loss: 0.011\n",
      "Starting Epoch:  574\n",
      "[575,    96] loss: 0.009\n",
      "Starting Epoch:  575\n",
      "[576,    96] loss: 0.019\n",
      "Starting Epoch:  576\n",
      "[577,    96] loss: 0.024\n",
      "Starting Epoch:  577\n",
      "[578,    96] loss: 0.013\n",
      "Starting Epoch:  578\n",
      "[579,    96] loss: 0.014\n",
      "Starting Epoch:  579\n",
      "[580,    96] loss: 0.014\n",
      "Starting Epoch:  580\n",
      "[581,    96] loss: 0.015\n",
      "Starting Epoch:  581\n",
      "[582,    96] loss: 0.009\n",
      "Starting Epoch:  582\n",
      "[583,    96] loss: 0.009\n",
      "Starting Epoch:  583\n",
      "[584,    96] loss: 0.030\n",
      "Starting Epoch:  584\n",
      "[585,    96] loss: 0.013\n",
      "Starting Epoch:  585\n",
      "[586,    96] loss: 0.014\n",
      "Starting Epoch:  586\n",
      "[587,    96] loss: 0.013\n",
      "Starting Epoch:  587\n",
      "[588,    96] loss: 0.032\n",
      "Starting Epoch:  588\n",
      "[589,    96] loss: 0.038\n",
      "Starting Epoch:  589\n",
      "[590,    96] loss: 0.022\n",
      "Starting Epoch:  590\n",
      "[591,    96] loss: 0.011\n",
      "Starting Epoch:  591\n",
      "[592,    96] loss: 0.020\n",
      "Starting Epoch:  592\n",
      "[593,    96] loss: 0.014\n",
      "Starting Epoch:  593\n",
      "[594,    96] loss: 0.007\n",
      "Starting Epoch:  594\n",
      "[595,    96] loss: 0.008\n",
      "Starting Epoch:  595\n",
      "[596,    96] loss: 0.004\n",
      "Starting Epoch:  596\n",
      "[597,    96] loss: 0.007\n",
      "Starting Epoch:  597\n",
      "[598,    96] loss: 0.008\n",
      "Starting Epoch:  598\n",
      "[599,    96] loss: 0.019\n",
      "Starting Epoch:  599\n",
      "[600,    96] loss: 0.018\n",
      "Starting Epoch:  600\n",
      "[601,    96] loss: 0.017\n",
      "Starting Epoch:  601\n",
      "[602,    96] loss: 0.027\n",
      "Starting Epoch:  602\n",
      "[603,    96] loss: 0.028\n",
      "Starting Epoch:  603\n",
      "[604,    96] loss: 0.008\n",
      "Starting Epoch:  604\n",
      "[605,    96] loss: 0.006\n",
      "Starting Epoch:  605\n",
      "[606,    96] loss: 0.007\n",
      "Starting Epoch:  606\n",
      "[607,    96] loss: 0.004\n",
      "Starting Epoch:  607\n",
      "[608,    96] loss: 0.026\n",
      "Starting Epoch:  608\n",
      "[609,    96] loss: 0.017\n",
      "Starting Epoch:  609\n",
      "[610,    96] loss: 0.015\n",
      "Starting Epoch:  610\n",
      "[611,    96] loss: 0.030\n",
      "Starting Epoch:  611\n",
      "[612,    96] loss: 0.027\n",
      "Starting Epoch:  612\n",
      "[613,    96] loss: 0.019\n",
      "Starting Epoch:  613\n",
      "[614,    96] loss: 0.013\n",
      "Starting Epoch:  614\n",
      "[615,    96] loss: 0.011\n",
      "Starting Epoch:  615\n",
      "[616,    96] loss: 0.012\n",
      "Starting Epoch:  616\n",
      "[617,    96] loss: 0.005\n",
      "Starting Epoch:  617\n",
      "[618,    96] loss: 0.010\n",
      "Starting Epoch:  618\n",
      "[619,    96] loss: 0.019\n",
      "Starting Epoch:  619\n",
      "[620,    96] loss: 0.035\n",
      "Starting Epoch:  620\n",
      "[621,    96] loss: 0.017\n",
      "Starting Epoch:  621\n",
      "[622,    96] loss: 0.015\n",
      "Starting Epoch:  622\n",
      "[623,    96] loss: 0.009\n",
      "Starting Epoch:  623\n",
      "[624,    96] loss: 0.007\n",
      "Starting Epoch:  624\n",
      "[625,    96] loss: 0.013\n",
      "Starting Epoch:  625\n",
      "[626,    96] loss: 0.017\n",
      "Starting Epoch:  626\n",
      "[627,    96] loss: 0.013\n",
      "Starting Epoch:  627\n",
      "[628,    96] loss: 0.012\n",
      "Starting Epoch:  628\n",
      "[629,    96] loss: 0.015\n",
      "Starting Epoch:  629\n",
      "[630,    96] loss: 0.020\n",
      "Starting Epoch:  630\n",
      "[631,    96] loss: 0.009\n",
      "Starting Epoch:  631\n",
      "[632,    96] loss: 0.011\n",
      "Starting Epoch:  632\n",
      "[633,    96] loss: 0.020\n",
      "Starting Epoch:  633\n",
      "[634,    96] loss: 0.015\n",
      "Starting Epoch:  634\n",
      "[635,    96] loss: 0.015\n",
      "Starting Epoch:  635\n",
      "[636,    96] loss: 0.024\n",
      "Starting Epoch:  636\n",
      "[637,    96] loss: 0.021\n",
      "Starting Epoch:  637\n",
      "[638,    96] loss: 0.014\n",
      "Starting Epoch:  638\n",
      "[639,    96] loss: 0.008\n",
      "Starting Epoch:  639\n",
      "[640,    96] loss: 0.013\n",
      "Starting Epoch:  640\n",
      "[641,    96] loss: 0.018\n",
      "Starting Epoch:  641\n",
      "[642,    96] loss: 0.007\n",
      "Starting Epoch:  642\n",
      "[643,    96] loss: 0.012\n",
      "Starting Epoch:  643\n",
      "[644,    96] loss: 0.014\n",
      "Starting Epoch:  644\n",
      "[645,    96] loss: 0.010\n",
      "Starting Epoch:  645\n",
      "[646,    96] loss: 0.021\n",
      "Starting Epoch:  646\n",
      "[647,    96] loss: 0.025\n",
      "Starting Epoch:  647\n",
      "[648,    96] loss: 0.033\n",
      "Starting Epoch:  648\n",
      "[649,    96] loss: 0.018\n",
      "Starting Epoch:  649\n",
      "[650,    96] loss: 0.017\n",
      "Starting Epoch:  650\n",
      "[651,    96] loss: 0.013\n",
      "Starting Epoch:  651\n",
      "[652,    96] loss: 0.018\n",
      "Starting Epoch:  652\n",
      "[653,    96] loss: 0.010\n",
      "Starting Epoch:  653\n",
      "[654,    96] loss: 0.012\n",
      "Starting Epoch:  654\n",
      "[655,    96] loss: 0.009\n",
      "Starting Epoch:  655\n",
      "[656,    96] loss: 0.003\n",
      "Starting Epoch:  656\n",
      "[657,    96] loss: 0.002\n",
      "Starting Epoch:  657\n",
      "[658,    96] loss: 0.003\n",
      "Starting Epoch:  658\n",
      "[659,    96] loss: 0.006\n",
      "Starting Epoch:  659\n",
      "[660,    96] loss: 0.013\n",
      "Starting Epoch:  660\n",
      "[661,    96] loss: 0.012\n",
      "Starting Epoch:  661\n",
      "[662,    96] loss: 0.015\n",
      "Starting Epoch:  662\n",
      "[663,    96] loss: 0.018\n",
      "Starting Epoch:  663\n",
      "[664,    96] loss: 0.029\n",
      "Starting Epoch:  664\n",
      "[665,    96] loss: 0.032\n",
      "Starting Epoch:  665\n",
      "[666,    96] loss: 0.033\n",
      "Starting Epoch:  666\n",
      "[667,    96] loss: 0.019\n",
      "Starting Epoch:  667\n",
      "[668,    96] loss: 0.016\n",
      "Starting Epoch:  668\n",
      "[669,    96] loss: 0.012\n",
      "Starting Epoch:  669\n",
      "[670,    96] loss: 0.014\n",
      "Starting Epoch:  670\n",
      "[671,    96] loss: 0.027\n",
      "Starting Epoch:  671\n",
      "[672,    96] loss: 0.012\n",
      "Starting Epoch:  672\n",
      "[673,    96] loss: 0.011\n",
      "Starting Epoch:  673\n",
      "[674,    96] loss: 0.013\n",
      "Starting Epoch:  674\n",
      "[675,    96] loss: 0.010\n",
      "Starting Epoch:  675\n",
      "[676,    96] loss: 0.008\n",
      "Starting Epoch:  676\n",
      "[677,    96] loss: 0.002\n",
      "Starting Epoch:  677\n",
      "[678,    96] loss: 0.015\n",
      "Starting Epoch:  678\n",
      "[679,    96] loss: 0.007\n",
      "Starting Epoch:  679\n",
      "[680,    96] loss: 0.008\n",
      "Starting Epoch:  680\n",
      "[681,    96] loss: 0.017\n",
      "Starting Epoch:  681\n",
      "[682,    96] loss: 0.022\n",
      "Starting Epoch:  682\n",
      "[683,    96] loss: 0.009\n",
      "Starting Epoch:  683\n",
      "[684,    96] loss: 0.008\n",
      "Starting Epoch:  684\n",
      "[685,    96] loss: 0.010\n",
      "Starting Epoch:  685\n",
      "[686,    96] loss: 0.014\n",
      "Starting Epoch:  686\n",
      "[687,    96] loss: 0.022\n",
      "Starting Epoch:  687\n",
      "[688,    96] loss: 0.027\n",
      "Starting Epoch:  688\n",
      "[689,    96] loss: 0.020\n",
      "Starting Epoch:  689\n",
      "[690,    96] loss: 0.014\n",
      "Starting Epoch:  690\n",
      "[691,    96] loss: 0.012\n",
      "Starting Epoch:  691\n",
      "[692,    96] loss: 0.010\n",
      "Starting Epoch:  692\n",
      "[693,    96] loss: 0.013\n",
      "Starting Epoch:  693\n",
      "[694,    96] loss: 0.005\n",
      "Starting Epoch:  694\n",
      "[695,    96] loss: 0.003\n",
      "Starting Epoch:  695\n",
      "[696,    96] loss: 0.005\n",
      "Starting Epoch:  696\n",
      "[697,    96] loss: 0.009\n",
      "Starting Epoch:  697\n",
      "[698,    96] loss: 0.009\n",
      "Starting Epoch:  698\n",
      "[699,    96] loss: 0.008\n",
      "Starting Epoch:  699\n",
      "[700,    96] loss: 0.023\n",
      "Starting Epoch:  700\n",
      "[701,    96] loss: 0.015\n",
      "Starting Epoch:  701\n",
      "[702,    96] loss: 0.022\n",
      "Starting Epoch:  702\n",
      "[703,    96] loss: 0.029\n",
      "Starting Epoch:  703\n",
      "[704,    96] loss: 0.025\n",
      "Starting Epoch:  704\n",
      "[705,    96] loss: 0.020\n",
      "Starting Epoch:  705\n",
      "[706,    96] loss: 0.020\n",
      "Starting Epoch:  706\n",
      "[707,    96] loss: 0.014\n",
      "Starting Epoch:  707\n",
      "[708,    96] loss: 0.012\n",
      "Starting Epoch:  708\n",
      "[709,    96] loss: 0.010\n",
      "Starting Epoch:  709\n",
      "[710,    96] loss: 0.013\n",
      "Starting Epoch:  710\n",
      "[711,    96] loss: 0.005\n",
      "Starting Epoch:  711\n",
      "[712,    96] loss: 0.004\n",
      "Starting Epoch:  712\n",
      "[713,    96] loss: 0.003\n",
      "Starting Epoch:  713\n",
      "[714,    96] loss: 0.004\n",
      "Starting Epoch:  714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[715,    96] loss: 0.008\n",
      "Starting Epoch:  715\n",
      "[716,    96] loss: 0.002\n",
      "Starting Epoch:  716\n",
      "[717,    96] loss: 0.003\n",
      "Starting Epoch:  717\n",
      "[718,    96] loss: 0.004\n",
      "Starting Epoch:  718\n",
      "[719,    96] loss: 0.011\n",
      "Starting Epoch:  719\n",
      "[720,    96] loss: 0.027\n",
      "Starting Epoch:  720\n",
      "[721,    96] loss: 0.031\n",
      "Starting Epoch:  721\n",
      "[722,    96] loss: 0.028\n",
      "Starting Epoch:  722\n",
      "[723,    96] loss: 0.035\n",
      "Starting Epoch:  723\n",
      "[724,    96] loss: 0.011\n",
      "Starting Epoch:  724\n",
      "[725,    96] loss: 0.013\n",
      "Starting Epoch:  725\n",
      "[726,    96] loss: 0.016\n",
      "Starting Epoch:  726\n",
      "[727,    96] loss: 0.020\n",
      "Starting Epoch:  727\n",
      "[728,    96] loss: 0.012\n",
      "Starting Epoch:  728\n",
      "[729,    96] loss: 0.012\n",
      "Starting Epoch:  729\n",
      "[730,    96] loss: 0.005\n",
      "Starting Epoch:  730\n",
      "[731,    96] loss: 0.003\n",
      "Starting Epoch:  731\n",
      "[732,    96] loss: 0.005\n",
      "Starting Epoch:  732\n",
      "[733,    96] loss: 0.011\n",
      "Starting Epoch:  733\n",
      "[734,    96] loss: 0.011\n",
      "Starting Epoch:  734\n",
      "[735,    96] loss: 0.015\n",
      "Nuevo modelo!: WOW ./model_test_734.pth\n",
      "Starting Epoch:  735\n",
      "[736,    96] loss: 0.009\n",
      "Starting Epoch:  736\n",
      "[737,    96] loss: 0.006\n",
      "Starting Epoch:  737\n",
      "[738,    96] loss: 0.013\n",
      "Starting Epoch:  738\n",
      "[739,    96] loss: 0.029\n",
      "Starting Epoch:  739\n",
      "[740,    96] loss: 0.022\n",
      "Starting Epoch:  740\n",
      "[741,    96] loss: 0.040\n",
      "Starting Epoch:  741\n",
      "[742,    96] loss: 0.006\n",
      "Starting Epoch:  742\n",
      "[743,    96] loss: 0.009\n",
      "Starting Epoch:  743\n",
      "[744,    96] loss: 0.011\n",
      "Starting Epoch:  744\n",
      "[745,    96] loss: 0.014\n",
      "Starting Epoch:  745\n",
      "[746,    96] loss: 0.010\n",
      "Starting Epoch:  746\n",
      "[747,    96] loss: 0.010\n",
      "Starting Epoch:  747\n",
      "[748,    96] loss: 0.025\n",
      "Starting Epoch:  748\n",
      "[749,    96] loss: 0.026\n",
      "Starting Epoch:  749\n",
      "[750,    96] loss: 0.023\n",
      "Starting Epoch:  750\n",
      "[751,    96] loss: 0.014\n",
      "Starting Epoch:  751\n",
      "[752,    96] loss: 0.006\n",
      "Starting Epoch:  752\n",
      "[753,    96] loss: 0.006\n",
      "Starting Epoch:  753\n",
      "[754,    96] loss: 0.010\n",
      "Starting Epoch:  754\n",
      "[755,    96] loss: 0.015\n",
      "Starting Epoch:  755\n",
      "[756,    96] loss: 0.016\n",
      "Starting Epoch:  756\n",
      "[757,    96] loss: 0.017\n",
      "Starting Epoch:  757\n",
      "[758,    96] loss: 0.011\n",
      "Starting Epoch:  758\n",
      "[759,    96] loss: 0.027\n",
      "Starting Epoch:  759\n",
      "[760,    96] loss: 0.015\n",
      "Starting Epoch:  760\n",
      "[761,    96] loss: 0.013\n",
      "Starting Epoch:  761\n",
      "[762,    96] loss: 0.012\n",
      "Starting Epoch:  762\n",
      "[763,    96] loss: 0.007\n",
      "Starting Epoch:  763\n",
      "[764,    96] loss: 0.004\n",
      "Starting Epoch:  764\n",
      "[765,    96] loss: 0.006\n",
      "Starting Epoch:  765\n",
      "[766,    96] loss: 0.004\n",
      "Starting Epoch:  766\n",
      "[767,    96] loss: 0.009\n",
      "Starting Epoch:  767\n",
      "[768,    96] loss: 0.005\n",
      "Starting Epoch:  768\n",
      "[769,    96] loss: 0.005\n",
      "Starting Epoch:  769\n",
      "[770,    96] loss: 0.007\n",
      "Starting Epoch:  770\n",
      "[771,    96] loss: 0.005\n",
      "Starting Epoch:  771\n",
      "[772,    96] loss: 0.016\n",
      "Starting Epoch:  772\n",
      "[773,    96] loss: 0.024\n",
      "Starting Epoch:  773\n",
      "[774,    96] loss: 0.027\n",
      "Starting Epoch:  774\n",
      "[775,    96] loss: 0.021\n",
      "Starting Epoch:  775\n",
      "[776,    96] loss: 0.007\n",
      "Starting Epoch:  776\n",
      "[777,    96] loss: 0.012\n",
      "Starting Epoch:  777\n",
      "[778,    96] loss: 0.013\n",
      "Starting Epoch:  778\n",
      "[779,    96] loss: 0.009\n",
      "Starting Epoch:  779\n",
      "[780,    96] loss: 0.014\n",
      "Starting Epoch:  780\n",
      "[781,    96] loss: 0.012\n",
      "Starting Epoch:  781\n",
      "[782,    96] loss: 0.012\n",
      "Starting Epoch:  782\n",
      "[783,    96] loss: 0.008\n",
      "Starting Epoch:  783\n",
      "[784,    96] loss: 0.006\n",
      "Starting Epoch:  784\n",
      "[785,    96] loss: 0.009\n",
      "Starting Epoch:  785\n",
      "[786,    96] loss: 0.010\n",
      "Starting Epoch:  786\n",
      "[787,    96] loss: 0.006\n",
      "Starting Epoch:  787\n",
      "[788,    96] loss: 0.004\n",
      "Starting Epoch:  788\n",
      "[789,    96] loss: 0.020\n",
      "Starting Epoch:  789\n",
      "[790,    96] loss: 0.021\n",
      "Starting Epoch:  790\n",
      "[791,    96] loss: 0.021\n",
      "Starting Epoch:  791\n",
      "[792,    96] loss: 0.014\n",
      "Starting Epoch:  792\n",
      "[793,    96] loss: 0.010\n",
      "Starting Epoch:  793\n",
      "[794,    96] loss: 0.007\n",
      "Starting Epoch:  794\n",
      "[795,    96] loss: 0.016\n",
      "Starting Epoch:  795\n",
      "[796,    96] loss: 0.017\n",
      "Starting Epoch:  796\n",
      "[797,    96] loss: 0.023\n",
      "Starting Epoch:  797\n",
      "[798,    96] loss: 0.006\n",
      "Starting Epoch:  798\n",
      "[799,    96] loss: 0.006\n",
      "Starting Epoch:  799\n",
      "[800,    96] loss: 0.011\n",
      "Starting Epoch:  800\n",
      "[801,    96] loss: 0.021\n",
      "Starting Epoch:  801\n",
      "[802,    96] loss: 0.019\n",
      "Starting Epoch:  802\n",
      "[803,    96] loss: 0.011\n",
      "Starting Epoch:  803\n",
      "[804,    96] loss: 0.012\n",
      "Starting Epoch:  804\n",
      "[805,    96] loss: 0.010\n",
      "Starting Epoch:  805\n",
      "[806,    96] loss: 0.003\n",
      "Starting Epoch:  806\n",
      "[807,    96] loss: 0.007\n",
      "Starting Epoch:  807\n",
      "[808,    96] loss: 0.008\n",
      "Starting Epoch:  808\n",
      "[809,    96] loss: 0.006\n",
      "Starting Epoch:  809\n",
      "[810,    96] loss: 0.005\n",
      "Starting Epoch:  810\n",
      "[811,    96] loss: 0.007\n",
      "Starting Epoch:  811\n",
      "[812,    96] loss: 0.005\n",
      "Starting Epoch:  812\n",
      "[813,    96] loss: 0.031\n",
      "Starting Epoch:  813\n",
      "[814,    96] loss: 0.022\n",
      "Starting Epoch:  814\n",
      "[815,    96] loss: 0.011\n",
      "Starting Epoch:  815\n",
      "[816,    96] loss: 0.008\n",
      "Starting Epoch:  816\n",
      "[817,    96] loss: 0.004\n",
      "Starting Epoch:  817\n",
      "[818,    96] loss: 0.004\n",
      "Starting Epoch:  818\n",
      "[819,    96] loss: 0.008\n",
      "Starting Epoch:  819\n",
      "[820,    96] loss: 0.004\n",
      "Starting Epoch:  820\n",
      "[821,    96] loss: 0.004\n",
      "Starting Epoch:  821\n",
      "[822,    96] loss: 0.008\n",
      "Starting Epoch:  822\n",
      "[823,    96] loss: 0.010\n",
      "Starting Epoch:  823\n",
      "[824,    96] loss: 0.002\n",
      "Starting Epoch:  824\n",
      "[825,    96] loss: 0.022\n",
      "Starting Epoch:  825\n",
      "[826,    96] loss: 0.031\n",
      "Starting Epoch:  826\n",
      "[827,    96] loss: 0.025\n",
      "Starting Epoch:  827\n",
      "[828,    96] loss: 0.024\n",
      "Starting Epoch:  828\n",
      "[829,    96] loss: 0.014\n",
      "Starting Epoch:  829\n",
      "[830,    96] loss: 0.012\n",
      "Starting Epoch:  830\n",
      "[831,    96] loss: 0.010\n",
      "Starting Epoch:  831\n",
      "[832,    96] loss: 0.019\n",
      "Starting Epoch:  832\n",
      "[833,    96] loss: 0.009\n",
      "Starting Epoch:  833\n",
      "[834,    96] loss: 0.017\n",
      "Starting Epoch:  834\n",
      "[835,    96] loss: 0.005\n",
      "Starting Epoch:  835\n",
      "[836,    96] loss: 0.004\n",
      "Starting Epoch:  836\n",
      "[837,    96] loss: 0.009\n",
      "Starting Epoch:  837\n",
      "[838,    96] loss: 0.015\n",
      "Starting Epoch:  838\n",
      "[839,    96] loss: 0.016\n",
      "Starting Epoch:  839\n",
      "[840,    96] loss: 0.004\n",
      "Starting Epoch:  840\n",
      "[841,    96] loss: 0.004\n",
      "Starting Epoch:  841\n",
      "[842,    96] loss: 0.011\n",
      "Starting Epoch:  842\n",
      "[843,    96] loss: 0.019\n",
      "Starting Epoch:  843\n",
      "[844,    96] loss: 0.009\n",
      "Starting Epoch:  844\n",
      "[845,    96] loss: 0.007\n",
      "Starting Epoch:  845\n",
      "[846,    96] loss: 0.006\n",
      "Starting Epoch:  846\n",
      "[847,    96] loss: 0.012\n",
      "Starting Epoch:  847\n",
      "[848,    96] loss: 0.005\n",
      "Starting Epoch:  848\n",
      "[849,    96] loss: 0.004\n",
      "Starting Epoch:  849\n",
      "[850,    96] loss: 0.006\n",
      "Starting Epoch:  850\n",
      "[851,    96] loss: 0.024\n",
      "Starting Epoch:  851\n",
      "[852,    96] loss: 0.042\n",
      "Starting Epoch:  852\n",
      "[853,    96] loss: 0.017\n",
      "Starting Epoch:  853\n",
      "[854,    96] loss: 0.018\n",
      "Starting Epoch:  854\n",
      "[855,    96] loss: 0.011\n",
      "Starting Epoch:  855\n",
      "[856,    96] loss: 0.014\n",
      "Starting Epoch:  856\n",
      "[857,    96] loss: 0.010\n",
      "Starting Epoch:  857\n",
      "[858,    96] loss: 0.005\n",
      "Starting Epoch:  858\n",
      "[859,    96] loss: 0.003\n",
      "Starting Epoch:  859\n",
      "[860,    96] loss: 0.006\n",
      "Starting Epoch:  860\n",
      "[861,    96] loss: 0.005\n",
      "Starting Epoch:  861\n",
      "[862,    96] loss: 0.004\n",
      "Starting Epoch:  862\n",
      "[863,    96] loss: 0.008\n",
      "Starting Epoch:  863\n",
      "[864,    96] loss: 0.005\n",
      "Starting Epoch:  864\n",
      "[865,    96] loss: 0.003\n",
      "Starting Epoch:  865\n",
      "[866,    96] loss: 0.008\n",
      "Starting Epoch:  866\n",
      "[867,    96] loss: 0.022\n",
      "Starting Epoch:  867\n",
      "[868,    96] loss: 0.016\n",
      "Starting Epoch:  868\n",
      "[869,    96] loss: 0.010\n",
      "Starting Epoch:  869\n",
      "[870,    96] loss: 0.006\n",
      "Starting Epoch:  870\n",
      "[871,    96] loss: 0.002\n",
      "Starting Epoch:  871\n",
      "[872,    96] loss: 0.004\n",
      "Starting Epoch:  872\n",
      "[873,    96] loss: 0.004\n",
      "Starting Epoch:  873\n",
      "[874,    96] loss: 0.006\n",
      "Starting Epoch:  874\n",
      "[875,    96] loss: 0.026\n",
      "Starting Epoch:  875\n",
      "[876,    96] loss: 0.023\n",
      "Starting Epoch:  876\n",
      "[877,    96] loss: 0.023\n",
      "Starting Epoch:  877\n",
      "[878,    96] loss: 0.006\n",
      "Starting Epoch:  878\n",
      "[879,    96] loss: 0.010\n",
      "Starting Epoch:  879\n",
      "[880,    96] loss: 0.026\n",
      "Starting Epoch:  880\n",
      "[881,    96] loss: 0.015\n",
      "Starting Epoch:  881\n",
      "[882,    96] loss: 0.016\n",
      "Starting Epoch:  882\n",
      "[883,    96] loss: 0.005\n",
      "Starting Epoch:  883\n",
      "[884,    96] loss: 0.007\n",
      "Starting Epoch:  884\n",
      "[885,    96] loss: 0.003\n",
      "Starting Epoch:  885\n",
      "[886,    96] loss: 0.011\n",
      "Starting Epoch:  886\n",
      "[887,    96] loss: 0.009\n",
      "Starting Epoch:  887\n",
      "[888,    96] loss: 0.010\n",
      "Starting Epoch:  888\n",
      "[889,    96] loss: 0.019\n",
      "Starting Epoch:  889\n",
      "[890,    96] loss: 0.009\n",
      "Starting Epoch:  890\n",
      "[891,    96] loss: 0.005\n",
      "Starting Epoch:  891\n",
      "[892,    96] loss: 0.008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Epoch:  892\n",
      "[893,    96] loss: 0.018\n",
      "Starting Epoch:  893\n",
      "[894,    96] loss: 0.025\n",
      "Starting Epoch:  894\n",
      "[895,    96] loss: 0.008\n",
      "Starting Epoch:  895\n",
      "[896,    96] loss: 0.019\n",
      "Starting Epoch:  896\n",
      "[897,    96] loss: 0.006\n",
      "Starting Epoch:  897\n",
      "[898,    96] loss: 0.013\n",
      "Starting Epoch:  898\n",
      "[899,    96] loss: 0.005\n",
      "Starting Epoch:  899\n",
      "[900,    96] loss: 0.009\n",
      "Starting Epoch:  900\n",
      "[901,    96] loss: 0.012\n",
      "Starting Epoch:  901\n",
      "[902,    96] loss: 0.007\n",
      "Starting Epoch:  902\n",
      "[903,    96] loss: 0.020\n",
      "Starting Epoch:  903\n",
      "[904,    96] loss: 0.019\n",
      "Starting Epoch:  904\n",
      "[905,    96] loss: 0.031\n",
      "Starting Epoch:  905\n",
      "[906,    96] loss: 0.017\n",
      "Starting Epoch:  906\n",
      "[907,    96] loss: 0.017\n",
      "Starting Epoch:  907\n",
      "[908,    96] loss: 0.008\n",
      "Starting Epoch:  908\n",
      "[909,    96] loss: 0.006\n",
      "Starting Epoch:  909\n",
      "[910,    96] loss: 0.016\n",
      "Starting Epoch:  910\n",
      "[911,    96] loss: 0.004\n",
      "Starting Epoch:  911\n",
      "[912,    96] loss: 0.014\n",
      "Starting Epoch:  912\n",
      "[913,    96] loss: 0.014\n",
      "Starting Epoch:  913\n",
      "[914,    96] loss: 0.004\n",
      "Starting Epoch:  914\n",
      "[915,    96] loss: 0.003\n",
      "Starting Epoch:  915\n",
      "[916,    96] loss: 0.002\n",
      "Starting Epoch:  916\n",
      "[917,    96] loss: 0.005\n",
      "Starting Epoch:  917\n",
      "[918,    96] loss: 0.003\n",
      "Starting Epoch:  918\n",
      "[919,    96] loss: 0.002\n",
      "Starting Epoch:  919\n",
      "[920,    96] loss: 0.011\n",
      "Starting Epoch:  920\n",
      "[921,    96] loss: 0.013\n",
      "Starting Epoch:  921\n",
      "[922,    96] loss: 0.014\n",
      "Starting Epoch:  922\n",
      "[923,    96] loss: 0.030\n",
      "Starting Epoch:  923\n",
      "[924,    96] loss: 0.026\n",
      "Starting Epoch:  924\n",
      "[925,    96] loss: 0.029\n",
      "Starting Epoch:  925\n",
      "[926,    96] loss: 0.015\n",
      "Starting Epoch:  926\n",
      "[927,    96] loss: 0.007\n",
      "Starting Epoch:  927\n",
      "[928,    96] loss: 0.004\n",
      "Starting Epoch:  928\n",
      "[929,    96] loss: 0.006\n",
      "Starting Epoch:  929\n",
      "[930,    96] loss: 0.006\n",
      "Starting Epoch:  930\n",
      "[931,    96] loss: 0.002\n",
      "Starting Epoch:  931\n",
      "[932,    96] loss: 0.012\n",
      "Starting Epoch:  932\n",
      "[933,    96] loss: 0.007\n",
      "Starting Epoch:  933\n",
      "[934,    96] loss: 0.006\n",
      "Starting Epoch:  934\n",
      "[935,    96] loss: 0.014\n",
      "Starting Epoch:  935\n",
      "[936,    96] loss: 0.005\n",
      "Starting Epoch:  936\n",
      "[937,    96] loss: 0.010\n",
      "Starting Epoch:  937\n",
      "[938,    96] loss: 0.009\n",
      "Starting Epoch:  938\n",
      "[939,    96] loss: 0.027\n",
      "Starting Epoch:  939\n",
      "[940,    96] loss: 0.011\n",
      "Starting Epoch:  940\n",
      "[941,    96] loss: 0.008\n",
      "Starting Epoch:  941\n",
      "[942,    96] loss: 0.003\n",
      "Starting Epoch:  942\n",
      "[943,    96] loss: 0.011\n",
      "Starting Epoch:  943\n",
      "[944,    96] loss: 0.014\n",
      "Starting Epoch:  944\n",
      "[945,    96] loss: 0.009\n",
      "Starting Epoch:  945\n",
      "[946,    96] loss: 0.003\n",
      "Starting Epoch:  946\n",
      "[947,    96] loss: 0.004\n",
      "Starting Epoch:  947\n",
      "[948,    96] loss: 0.016\n",
      "Starting Epoch:  948\n",
      "[949,    96] loss: 0.030\n",
      "Starting Epoch:  949\n",
      "[950,    96] loss: 0.008\n",
      "Starting Epoch:  950\n",
      "[951,    96] loss: 0.020\n",
      "Starting Epoch:  951\n",
      "[952,    96] loss: 0.008\n",
      "Starting Epoch:  952\n",
      "[953,    96] loss: 0.003\n",
      "Starting Epoch:  953\n",
      "[954,    96] loss: 0.005\n",
      "Starting Epoch:  954\n",
      "[955,    96] loss: 0.004\n",
      "Starting Epoch:  955\n",
      "[956,    96] loss: 0.002\n",
      "Starting Epoch:  956\n",
      "[957,    96] loss: 0.003\n",
      "Starting Epoch:  957\n",
      "[958,    96] loss: 0.004\n",
      "Starting Epoch:  958\n",
      "[959,    96] loss: 0.005\n",
      "Starting Epoch:  959\n",
      "[960,    96] loss: 0.007\n",
      "Starting Epoch:  960\n",
      "[961,    96] loss: 0.017\n",
      "Starting Epoch:  961\n",
      "[962,    96] loss: 0.017\n",
      "Starting Epoch:  962\n",
      "[963,    96] loss: 0.016\n",
      "Starting Epoch:  963\n",
      "[964,    96] loss: 0.007\n",
      "Starting Epoch:  964\n",
      "[965,    96] loss: 0.004\n",
      "Starting Epoch:  965\n",
      "[966,    96] loss: 0.005\n",
      "Starting Epoch:  966\n",
      "[967,    96] loss: 0.013\n",
      "Starting Epoch:  967\n",
      "[968,    96] loss: 0.010\n",
      "Starting Epoch:  968\n",
      "[969,    96] loss: 0.004\n",
      "Starting Epoch:  969\n",
      "[970,    96] loss: 0.004\n",
      "Starting Epoch:  970\n",
      "[971,    96] loss: 0.003\n",
      "Starting Epoch:  971\n",
      "[972,    96] loss: 0.016\n",
      "Starting Epoch:  972\n",
      "[973,    96] loss: 0.011\n",
      "Starting Epoch:  973\n",
      "[974,    96] loss: 0.006\n",
      "Starting Epoch:  974\n",
      "[975,    96] loss: 0.012\n",
      "Starting Epoch:  975\n",
      "[976,    96] loss: 0.015\n",
      "Starting Epoch:  976\n",
      "[977,    96] loss: 0.014\n",
      "Starting Epoch:  977\n",
      "[978,    96] loss: 0.014\n",
      "Starting Epoch:  978\n",
      "[979,    96] loss: 0.005\n",
      "Starting Epoch:  979\n",
      "[980,    96] loss: 0.006\n",
      "Starting Epoch:  980\n",
      "[981,    96] loss: 0.006\n",
      "Starting Epoch:  981\n",
      "[982,    96] loss: 0.017\n",
      "Starting Epoch:  982\n",
      "[983,    96] loss: 0.020\n",
      "Starting Epoch:  983\n",
      "[984,    96] loss: 0.017\n",
      "Starting Epoch:  984\n",
      "[985,    96] loss: 0.014\n",
      "Starting Epoch:  985\n",
      "[986,    96] loss: 0.019\n",
      "Starting Epoch:  986\n",
      "[987,    96] loss: 0.008\n",
      "Starting Epoch:  987\n",
      "[988,    96] loss: 0.006\n",
      "Starting Epoch:  988\n",
      "[989,    96] loss: 0.007\n",
      "Starting Epoch:  989\n",
      "[990,    96] loss: 0.009\n",
      "Starting Epoch:  990\n",
      "[991,    96] loss: 0.010\n",
      "Starting Epoch:  991\n",
      "[992,    96] loss: 0.003\n",
      "Starting Epoch:  992\n",
      "[993,    96] loss: 0.002\n",
      "Starting Epoch:  993\n",
      "[994,    96] loss: 0.006\n",
      "Starting Epoch:  994\n",
      "[995,    96] loss: 0.016\n",
      "Starting Epoch:  995\n",
      "[996,    96] loss: 0.016\n",
      "Starting Epoch:  996\n",
      "[997,    96] loss: 0.011\n",
      "Starting Epoch:  997\n",
      "[998,    96] loss: 0.007\n",
      "Starting Epoch:  998\n",
      "[999,    96] loss: 0.010\n",
      "Starting Epoch:  999\n",
      "[1000,    96] loss: 0.016\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "correctAnt=0\n",
    "for epoch in range(1000):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    print('Starting Epoch: ',epoch)\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        # inputs, labels = data\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "            \n",
    "        if i % 96 == 95:    # print every 100 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 100))\n",
    "            running_loss = 0.0\n",
    "            if epoch>100:\n",
    "                correct = 0\n",
    "                with torch.no_grad():\n",
    "                    for data2 in testloader:\n",
    "                        # images, labels = data\n",
    "                        images2, labels2 = data2[0].to(device), data2[1].to(device)\n",
    "                        outputs = net(images2)\n",
    "                        _, predicted = torch.max(outputs.data, 1)\n",
    "                        correct += (predicted == labels2).sum().item()\n",
    "                    if correct > correctAnt:\n",
    "                        correctAnt = correct\n",
    "                        if epoch<400:\n",
    "                            torch.save(net.state_dict(), PATH)\n",
    "                            print(\"Nuevo modelo!\")\n",
    "                        else:\n",
    "                            torch.save(net.state_dict(), './model_test_'+str(epoch)+'.pth')\n",
    "                            print(\"Nuevo modelo!: WOW\",'./model_test_'+str(epoch)+'.pth')\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './model_test_734.pth'\n",
    "torch.save(net.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(testloader)\n",
    "images, labels = dataiter.next()\n",
    "images = images.to(device)\n",
    "labels = labels.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/lcarranza/.cache/torch/hub/pytorch_vision_v0.5.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let's use 2 GPUs!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Inception3(\n",
       "  (Conv2d_1a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_2a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_2b_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_3b_1x1): BasicConv2d(\n",
       "    (conv): Conv2d(64, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(80, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Conv2d_4a_3x3): BasicConv2d(\n",
       "    (conv): Conv2d(80, 192, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  )\n",
       "  (Mixed_5b): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_5c): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_5d): InceptionA(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 48, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(48, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch5x5_2): BasicConv2d(\n",
       "      (conv): Conv2d(48, 64, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6a): InceptionB(\n",
       "    (branch3x3): BasicConv2d(\n",
       "      (conv): Conv2d(288, 384, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(288, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(64, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(64, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(96, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6b): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(128, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(128, 128, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(128, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(128, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6c): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6d): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(160, 160, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(160, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(160, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_6e): InceptionC(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_4): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7dbl_5): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_7a): InceptionD(\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 320, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_2): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(1, 7), stride=(1, 1), padding=(0, 3), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_3): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(7, 1), stride=(1, 1), padding=(3, 0), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch7x7x3_4): BasicConv2d(\n",
       "      (conv): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_7b): InceptionE(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(1280, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (Mixed_7c): InceptionE(\n",
       "    (branch1x1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(320, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3_2b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_1): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 448, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(448, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_2): BasicConv2d(\n",
       "      (conv): Conv2d(448, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3a): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(1, 3), stride=(1, 1), padding=(0, 1), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch3x3dbl_3b): BasicConv2d(\n",
       "      (conv): Conv2d(384, 384, kernel_size=(3, 1), stride=(1, 1), padding=(1, 0), bias=False)\n",
       "      (bn): BatchNorm2d(384, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (branch_pool): BasicConv2d(\n",
       "      (conv): Conv2d(2048, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(192, eps=0.001, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = torch.hub.load('pytorch/vision:v0.5.0', 'inception_v3', pretrained=False, aux_logits=False)\n",
    "if torch.cuda.device_count() > 1:\n",
    "  print(\"Let's use\", torch.cuda.device_count(), \"GPUs!\")\n",
    "  # dim = 0 [30, xxx] -> [10, ...], [10, ...], [10, ...] on 3 GPUs\n",
    "  # net = nn.DataParallel(net)\n",
    "net.to(device)\n",
    "net.load_state_dict(torch.load(PATH))\n",
    "net.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = net(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted:  jamon nueces caramelo  jugo\n"
     ]
    }
   ],
   "source": [
    "_, predicted = torch.max(outputs, 1)\n",
    "\n",
    "print('Predicted: ', ' '.join('%5s' % testset.idx_to_class[predicted[j].item()]\n",
    "                              for j in range(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 63 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        # images, labels = data\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of aceite : 66 %\n",
      "Accuracy of  agua : 70 %\n",
      "Accuracy of arroz : 44 %\n",
      "Accuracy of azucar : 71 %\n",
      "Accuracy of  cafe : 57 %\n",
      "Accuracy of caramelo : 66 %\n",
      "Accuracy of cereal : 50 %\n",
      "Accuracy of chips : 45 %\n",
      "Accuracy of chocolate : 63 %\n",
      "Accuracy of especias : 46 %\n",
      "Accuracy of frijoles : 62 %\n",
      "Accuracy of gaseosa : 81 %\n",
      "Accuracy of harina : 71 %\n",
      "Accuracy of jamon : 73 %\n",
      "Accuracy of  jugo : 63 %\n",
      "Accuracy of leche : 60 %\n",
      "Accuracy of  maiz : 83 %\n",
      "Accuracy of  miel : 75 %\n",
      "Accuracy of nueces : 50 %\n",
      "Accuracy of pasta : 72 %\n",
      "Accuracy of pescado : 85 %\n",
      "Accuracy of salsatomate : 90 %\n",
      "Accuracy of    te : 50 %\n",
      "Accuracy of torta : 50 %\n",
      "Accuracy of vinagre : 50 %\n"
     ]
    }
   ],
   "source": [
    "class_correct = list(0. for i in range(25))\n",
    "class_total = list(0. for i in range(25))\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        # images, labels = data\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        outputs = net(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        c = (predicted == labels).squeeze()\n",
    "        for i in range(len(c)):\n",
    "            label = labels[i]\n",
    "            class_correct[label] += c[i].item()\n",
    "            class_total[label] += 1\n",
    "\n",
    "\n",
    "for i in range(25):\n",
    "    print('Accuracy of %5s : %2d %%' % (\n",
    "        trainset.idx_to_class[i], 100 * class_correct[i] / class_total[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Era 39%\n",
    "Era 46%\n",
    "Era 51% 200\n",
    "Sigue 51% 400\n",
    "Es 63% 734"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
